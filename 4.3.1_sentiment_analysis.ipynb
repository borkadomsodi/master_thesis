{"cells":[{"cell_type":"markdown","metadata":{"id":"FGJAUhGs_bLg"},"source":["# Sentiment Analysis"]},{"cell_type":"markdown","metadata":{"id":"7QIvQEzH_jMy"},"source":["## 1. Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCkrwWq3BUXS"},"outputs":[],"source":["# Install packages\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rU3eoDHg_-mS"},"outputs":[],"source":["# Import Packages\n","import pandas as pd\n","from transformers import pipeline\n","import re\n","from google.colab import files"]},{"cell_type":"markdown","metadata":{"id":"IeZhaaWtBfcZ"},"source":["## 2. Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG7esgofDsnt"},"outputs":[],"source":["# Comments Data\n","\n","# Load data in from files\n","fp = \"2.2_comments_data.xlsx\"\n","comments_data = pd.read_excel(fp, header=0)\n","\n","# View the data frame to get a quick overview\n","comments_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Submissions Data\n","\n","# Load data in from files\n","fp = \"2.1_submissions_data.xlsx\"\n","submissions_data = pd.read_excel(fp, header=0)\n","\n","# View the data frame to get a quick overview\n","submissions_data"]},{"cell_type":"markdown","metadata":{"id":"OzN3aOokEC9z"},"source":["## 3. Sentiment Analysis Model Testing"]},{"cell_type":"markdown","metadata":{"id":"H6_dhGjkBdbQ"},"source":["### 3.0. Specify Test User"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ofn7GqnHELAl"},"outputs":[],"source":["# Define a test user\n","user = comments_data['submission_author'].iloc[0]\n","\n","# Define test dataset based on the test user\n","filtered_comments = comments_data[(comments_data['submission_author'] == user) |\n","                                  (comments_data['parent_comment_author'] == user)]\n","\n","# Filtering out rows where comment_author=user\n","filtered_comments = filtered_comments[~(filtered_comments['comment_author'] == user)]\n","\n","# View df\n","filtered_comments"]},{"cell_type":"markdown","metadata":{"id":"iLUgV97GJCp3"},"source":["### 3.1. Model 1: cardiffnlp/twitter-roberta-base-sentiment-latest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKRBl__--8mQ"},"outputs":[],"source":["# Load the sentiment analysis model\n","sentiment_analysis = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n","\n","# Function to get sentiment label for a text\n","def get_sentiment_label(text):\n","    result = sentiment_analysis(text)\n","    label = result[0]['label']\n","    return label\n","\n","# Function to get sentiment score for a text\n","def get_sentiment_score(text):\n","    result = sentiment_analysis(text)\n","    score = result[0]['score']\n","    return score\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment labels\n","filtered_comments['sentiment_label1'] = filtered_comments['comment_body'].apply(get_sentiment_label)\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment scores\n","filtered_comments['sentiment_score1'] = filtered_comments['comment_body'].apply(get_sentiment_score)\n","\n","# Print Results\n","for index, row in filtered_comments.iterrows():\n","    print(\"Comment Body:\", row['comment_body'])\n","    print(\"Sentiment Label 1:\", row['sentiment_label1'])\n","    print(\"Sentiment Score 1:\", row['sentiment_score1'])\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"iH0p06ZwIziZ"},"source":["This model works fairly well. The scores are all over the place, but the labels seem to be valid."]},{"cell_type":"markdown","metadata":{"id":"g7WRXgj3I4Gd"},"source":["### 3.2. Model 2: mwkby/distilbert-base-uncased-sentiment-reddit-crypto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95mLlZwFq2ye"},"outputs":[],"source":["# Load the sentiment analysis model\n","sentiment_analysis = pipeline('sentiment-analysis', model='mwkby/distilbert-base-uncased-sentiment-reddit-crypto')\n","\n","# Function to get sentiment label for a text\n","def get_sentiment_label(text):\n","    result = sentiment_analysis(text)\n","    label = result[0]['label']\n","    return label\n","\n","# Function to get sentiment score for a text\n","def get_sentiment_score(text):\n","    result = sentiment_analysis(text)\n","    score = result[0]['score']\n","    return score\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment labels\n","filtered_comments['sentiment_label2'] = filtered_comments['comment_body'].apply(get_sentiment_label)\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment scores\n","filtered_comments['sentiment_score2'] = filtered_comments['comment_body'].apply(get_sentiment_score)\n","\n","# Print Results\n","for index, row in filtered_comments.iterrows():\n","    print(\"Comment Body:\", row['comment_body'])\n","    print(\"Sentiment Label 2:\", row['sentiment_label2'])\n","    print(\"Sentiment Score 2:\", row['sentiment_score2'])\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"lQdOc1dhLa5F"},"source":["The scores are high and don't have much variability, which is a bad sign. Labels could work but there are too many positives and no neutrals showed up which is, again, a bad sign. This model didn't work very well."]},{"cell_type":"markdown","metadata":{"id":"1ZUAHrmYLieM"},"source":["### 3.3. Model 3: minh21/XLNet-Reddit-Sentiment-Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3J6YOS9soYE"},"outputs":[],"source":["# Load the sentiment analysis model\n","sentiment_analysis = pipeline('sentiment-analysis', model='minh21/XLNet-Reddit-Sentiment-Analysis')\n","\n","# Function to get sentiment label for a text\n","def get_sentiment_label(text):\n","    result = sentiment_analysis(text)\n","    label = result[0]['label']\n","    return label\n","\n","# Function to get sentiment score for a text\n","def get_sentiment_score(text):\n","    result = sentiment_analysis(text)\n","    score = result[0]['score']\n","    return score\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment labels\n","filtered_comments['sentiment_label3'] = filtered_comments['comment_body'].apply(get_sentiment_label)\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment scores\n","filtered_comments['sentiment_score3'] = filtered_comments['comment_body'].apply(get_sentiment_score)\n","\n","# Print Results\n","for index, row in filtered_comments.iterrows():\n","    print(\"Comment Body:\", row['comment_body'])\n","    print(\"Sentiment Label 3:\", row['sentiment_label3'])\n","    print(\"Sentiment Score 3:\", row['sentiment_score3'])\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"ROfEJHz7OGoK"},"source":["The labels of this model seem to be promising, however, there is no reliable documentation to be found where their meaning is defined.This means this model is rather unreliable."]},{"cell_type":"markdown","metadata":{"id":"vE83L3b9OObW"},"source":["### 3.4. Model 4: akshataupadhye/finetuning-sentiment-model-reddit-data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2BfX2t-s4Hp"},"outputs":[],"source":["# Load the sentiment analysis model\n","sentiment_analysis = pipeline('sentiment-analysis', model='akshataupadhye/finetuning-sentiment-model-reddit-data')\n","\n","# Function to get sentiment label for a text\n","def get_sentiment_label(text):\n","    result = sentiment_analysis(text)\n","    label = result[0]['label']\n","    return label\n","\n","# Function to get sentiment score for a text\n","def get_sentiment_score(text):\n","    result = sentiment_analysis(text)\n","    score = result[0]['score']\n","    return score\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment labels\n","filtered_comments['sentiment_label4'] = filtered_comments['comment_body'].apply(get_sentiment_label)\n","\n","# Apply the sentiment analysis model to each comment_body to get sentiment scores\n","filtered_comments['sentiment_score4'] = filtered_comments['comment_body'].apply(get_sentiment_score)\n","\n","# Print Results\n","for index, row in filtered_comments.iterrows():\n","    print(\"Comment Body:\", row['comment_body'])\n","    print(\"Sentiment Label 4:\", row['sentiment_label4'])\n","    print(\"Sentiment Score 4:\", row['sentiment_score4'])\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"27Z9cir6vdmr"},"source":["Same issue as with the previous model.\n","\n","In sum, the first model seems to be the most reliable due to three things.\n","\n","1. This was trained on the largest amount of data, namely on ~124M tweets.\n","\n","2. This has the most comprehensive documentation.\n","\n","3. The labels of this model were proven to be the most accurate, validated by human judgement."]},{"cell_type":"markdown","metadata":{"id":"VVTfYl0iy0Oe"},"source":["## 4. Run the selected model"]},{"cell_type":"markdown","metadata":{},"source":["### 4.1. Comments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_o2PpL7DcU5"},"outputs":[],"source":["# Preprocess text (username and link placeholders)\n","def preprocess(text):\n","    if isinstance(text, str):\n","        new_text = []\n","        for t in text.split(\" \"):\n","            t = '@user' if t.startswith('@') and len(t) > 1 else t\n","            t = 'http' if t.startswith('http') else t\n","            new_text.append(t)\n","        return \" \".join(new_text)\n","    else:\n","        return \"\"\n","\n","comments_data['comment_body_prep'] = comments_data['comment_body'].apply(preprocess)\n","\n","comments_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2_qbU2nyzkE"},"outputs":[],"source":["# Load the sentiment analysis model\n","sentiment_analysis = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n","\n","# Function to map sentiment labels to numeric values\n","def map_sentiment_label(sentiment):\n","    if sentiment == 'negative':\n","        return -1\n","    elif sentiment == 'neutral':\n","        return 0\n","    elif sentiment == 'positive':\n","        return 1\n","    else:\n","        return None  # Handle unknown sentiment labels\n","\n","# Get sentiment label for a text, handling too long comments\n","def get_sentiment_label(text):\n","    try:\n","        result = sentiment_analysis(text)\n","        label = result[0]['label']\n","        return map_sentiment_label(label)\n","    except Exception as e:\n","        return \"NA\"\n","\n","# Apply the sentiment analysis model\n","comments_data['sentiment_label'] = comments_data['comment_body_prep'].apply(get_sentiment_label)\n","\n","# Print Results\n","comments_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2. Submissions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Preprocess text (username and link placeholders)\n","def preprocess(text):\n","    if isinstance(text, str):\n","        new_text = []\n","        for t in text.split(\" \"):\n","            t = '@user' if t.startswith('@') and len(t) > 1 else t\n","            t = 'http' if t.startswith('http') else t\n","            new_text.append(t)\n","        return \" \".join(new_text)\n","    else:\n","        return \"\"\n","\n","submissions_data['body_prep'] = submissions_data['body'].apply(preprocess)\n","\n","submissions_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the sentiment analysis model\n","sentiment_analysis = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n","\n","# Function to map sentiment labels to numeric values\n","def map_sentiment_label(sentiment):\n","    if sentiment == 'negative':\n","        return -1\n","    elif sentiment == 'neutral':\n","        return 0\n","    elif sentiment == 'positive':\n","        return 1\n","    else:\n","        return None  # Handle unknown sentiment labels\n","\n","# Get sentiment label for a text, handling too long comments\n","def get_sentiment_label(text):\n","    try:\n","        result = sentiment_analysis(text)\n","        label = result[0]['label']\n","        return map_sentiment_label(label)\n","    except Exception as e:\n","        return \"NA\"\n","\n","# Apply the sentiment analysis model\n","submissions_data['sentiment_label'] = submissions_data['body_prep'].apply(get_sentiment_label)\n","\n","# Print Results\n","submissions_data.head()"]},{"cell_type":"markdown","metadata":{"id":"BRHhXhx5zdfI"},"source":["## 5. Save & Export"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Comments\n","comments_data.to_excel('4.3.1.1_comments_data_sa.xlsx', index=False)\n","\n","# Download the Excel file\n","files.download('4.3.1.1_comments_data_sa.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":7710,"status":"ok","timestamp":1708872650314,"user":{"displayName":"L Bíborka Dömsödi","userId":"11712730041989952327"},"user_tz":-60},"id":"W-e96xiNjUwH","outputId":"0932506a-703f-4ed6-9b16-ee60fc8e3609"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_5fdf42d4-89de-45ab-a3fb-5fd66478e6a7\", \"5.3.2_comments_data_sa.xlsx\", 2260290)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Submissions\n","submissions_data.to_excel('4.3.1.2_submissions_data_sa.xlsx', index=False)\n","\n","# Download the Excel file\n","files.download('4.3.1.2_submissions_data_sa.xlsx')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMNGF0I6hT/hk/QoTOMMDfg","collapsed_sections":["7QIvQEzH_jMy","IeZhaaWtBfcZ","H6_dhGjkBdbQ","iLUgV97GJCp3","g7WRXgj3I4Gd","1ZUAHrmYLieM","vE83L3b9OObW","VVTfYl0iy0Oe","BRHhXhx5zdfI"],"provenance":[{"file_id":"17EPs8tveyGSCYhoYWb4Lk9jYoGcUZ0jd","timestamp":1714226852667}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
